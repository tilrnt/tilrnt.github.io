<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Setting up custom learning rate schedulers in TF 2.0 | Today I Learnt</title>
<meta name="generator" content="Jekyll v4.3.2" />
<meta property="og:title" content="Setting up custom learning rate schedulers in TF 2.0" />
<meta name="author" content="Chee Yeo 2023" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="In ML training, it is essential to understand and utilize an approach to adjusting the learning rate of a model. It helps with applying regularization to the model to prevent overfitting." />
<meta property="og:description" content="In ML training, it is essential to understand and utilize an approach to adjusting the learning rate of a model. It helps with applying regularization to the model to prevent overfitting." />
<link rel="canonical" href="https://tilrnt.github.io/machine-learning/tensorflow/tf2.0/2022/05/08/tensorflow-learning-rate-scheduler.html" />
<meta property="og:url" content="https://tilrnt.github.io/machine-learning/tensorflow/tf2.0/2022/05/08/tensorflow-learning-rate-scheduler.html" />
<meta property="og:site_name" content="Today I Learnt" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-05-08T01:00:00+01:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Setting up custom learning rate schedulers in TF 2.0" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Chee Yeo 2023"},"dateModified":"2022-05-08T01:00:00+01:00","datePublished":"2022-05-08T01:00:00+01:00","description":"In ML training, it is essential to understand and utilize an approach to adjusting the learning rate of a model. It helps with applying regularization to the model to prevent overfitting.","headline":"Setting up custom learning rate schedulers in TF 2.0","mainEntityOfPage":{"@type":"WebPage","@id":"https://tilrnt.github.io/machine-learning/tensorflow/tf2.0/2022/05/08/tensorflow-learning-rate-scheduler.html"},"url":"https://tilrnt.github.io/machine-learning/tensorflow/tf2.0/2022/05/08/tensorflow-learning-rate-scheduler.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="https://tilrnt.github.io/feed.xml" title="Today I Learnt" /></head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Today I Learnt</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Setting up custom learning rate schedulers in TF 2.0</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2022-05-08T01:00:00+01:00" itemprop="datePublished">May 8, 2022
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p>In ML training, it is essential to understand and utilize an approach to adjusting the learning rate of a model. It helps with applying regularization to the model to prevent overfitting.</p>

<p><code class="language-plaintext highlighter-rouge">Learning rate decay</code> is an example of a regularization technique which dynamically adjusts the learning rate of a model during its training process. It reduces the learning rate of the model over epochs or steps.</p>

<p>There are 2 main approaches to using learning rate schedulers in TF 2.0:</p>

<ul>
  <li>
    <p>Using the callback <code class="language-plaintext highlighter-rouge">LearningRateSchduler</code> and applying your own function</p>
  </li>
  <li>
    <p>Creating a custom subclass of <code class="language-plaintext highlighter-rouge">tf.keras.optimizers.schedules.LearningRateSchedule</code></p>
  </li>
</ul>

<p>What is the difference ? The main difference is that approach 1 is meant to be called from the <code class="language-plaintext highlighter-rouge">callbacks</code> kwargs in the <code class="language-plaintext highlighter-rouge">model.fit</code> call whereas the second approach allows you to pass it as an input to the optimizer <code class="language-plaintext highlighter-rouge">learning_rate</code> kwarg.</p>

<h3 id="1-using-the-learningratescheduler-callback">1. Using the LearningRateScheduler callback</h3>

<p>The callback class requires a function of the form:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def my_lr_scheduler(epoch, lr):
  # custom code to adjust learning rate

  # return new learning rate
</code></pre></div></div>

<p>The custom function needs to handle 2 parameters: <code class="language-plaintext highlighter-rouge">epoch</code> and <code class="language-plaintext highlighter-rouge">lr</code> (learning rate). This callback will be invoked at the beginning of every epoch, passing in the current epoch and optimizer learning rate. The custom function will need to return the new learning rate value, which the callback uses to update the learning rate of the optimizer</p>

<p>To invoke the example callback above:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">tensorflow.keras.callbacks</span> <span class="kn">import</span> <span class="n">LearningRateScheduler</span>
<span class="p">...</span>

<span class="n">mymodel</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span>
	<span class="p">...</span>
	<span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">LearningRateScheduler</span><span class="p">(</span><span class="n">my_lr_scheduler</span><span class="p">)]</span>
<span class="p">)</span></code></pre></figure>

<h3 id="2-subclass-the-learningrateschedule-base-class">2. Subclass the LearningRateSchedule base class</h3>

<p>The <code class="language-plaintext highlighter-rouge">LearningRateSchedule</code> base class adjusts the learning rate per step / batch of training, rather than over an entire epoch. This is useful if you are training your model in steps rather than epochs. For example, in GAN training</p>

<p>Example of creating a custom LR scheduler class:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">tensorflow.keras.optimizers.schedules</span> <span class="kn">import</span> <span class="n">LearningRateSchedule</span>

<span class="k">class</span> <span class="nc">LinearLRSchedule</span><span class="p">(</span><span class="n">LearningRateSchedule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">initial_learning_rate</span><span class="p">,</span> <span class="n">max_iters</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LinearLRSchedule</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">initial_learning_rate</span> <span class="o">=</span> <span class="n">initial_learning_rate</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">max_iters</span> <span class="o">=</span> <span class="n">max_iters</span>

    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">step</span><span class="p">):</span>
        <span class="n">new_lr</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">initial_learning_rate</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="n">step</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">max_iters</span><span class="p">)))</span>
        <span class="k">return</span> <span class="n">new_lr</span>

    <span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="s">"initial_learning_rate"</span><span class="p">:</span> <span class="bp">self</span><span class="p">.</span><span class="n">initial_learning_rate</span><span class="p">,</span>
            <span class="s">"max_iters"</span><span class="p">:</span> <span class="bp">self</span><span class="p">.</span><span class="n">max_iters</span>
        <span class="p">}</span></code></pre></figure>

<p>During training, the subclass would be passed directly into the <code class="language-plaintext highlighter-rouge">learning_rate</code> kwargs of an optimizer object:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">LinearLRSchedule</span><span class="p">(</span><span class="mf">1e-1</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span></code></pre></figure>

<h3 id="resources">Resources</h3>
<p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/LearningRateScheduler">LearningRateScheduler Callback</a></p>

<p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/LearningRateSchedule">LearningRateSchedule Class</a></p>


  </div><a class="u-url" href="/machine-learning/tensorflow/tf2.0/2022/05/08/tensorflow-learning-rate-scheduler.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">
    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">
            
              Chee Yeo 2023
            
            </li>
            
        </ul>
      </div>

      <div class="footer-col footer-col-2">
        <ul class="social-media-list">
          
          <li>
            <a href="https://github.com/cheeyeo"><span class="icon icon--github"><svg viewBox="0 0 16 16" width="16px" height="16px"><path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/></svg>
</span><span class="username">cheeyeo</span></a>

          </li>
          

          
        </ul>
      </div>

      <div class="footer-col footer-col-3">
        <p>A collection of notes on things I learn on a daily basis.</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
